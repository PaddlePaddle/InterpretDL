{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discovering Important Words for Sentiments With NormLIME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook loads the pretrained Bi-LSTM model following [PaddleNLP TextClassification](https://github.com/PaddlePaddle/models/tree/release/2.0-beta/PaddleNLP/examples/text_classification/rnn) and performs sentiment analysis on reviews data. The full official PaddlePaddle sentiment classification tutorial can be found [here](https://github.com/PaddlePaddle/models/tree/release/2.0-beta/PaddleNLP/examples/text_classification). \n",
    "\n",
    "NormLIME method aggregates local models into global and class-specific interpretations. It is effective at recognizing important features. In this notebook, we use NormLIME method, specifically `NormLIMENLPInterpreter`, to discover the words that contribute the most to positive and negative sentiment predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install PaddleNLP first:\n",
    "``` bash\n",
    "pip install setuptools_scm \n",
    "pip install --upgrade paddlenlp==2.1 \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "import numpy as np\n",
    "import interpretdl as it\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the word dict and specify the pretrained model path. Define the `unk_id` to be the word id for *\\[UNK\\]* token. Other possible choices include empty token *\\\"\\\"* and *\\[PAD\\]* token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow our tutorial (`tutorials/bilstm-zh-chnsenticorp-tutorials.ipynb`) to get the pretrained weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vocab(vocab_file):\n",
    "    \"\"\"Loads a vocabulary file into a dictionary.\"\"\"\n",
    "    vocab = {}\n",
    "    with open(vocab_file, \"r\", encoding=\"utf-8\") as reader:\n",
    "        tokens = reader.readlines()\n",
    "    for index, token in enumerate(tokens):\n",
    "        token = token.rstrip(\"\\n\").split(\"\\t\")[0]\n",
    "        vocab[token] = index\n",
    "    return vocab\n",
    "\n",
    "PARAMS_PATH = \"assets/final.pdparams\"\n",
    "VOCAB_PATH = \"assets/senta_word_dict.txt\"\n",
    "\n",
    "vocab = load_vocab(VOCAB_PATH)\n",
    "unk_token_id = vocab['[UNK]']\n",
    "pad_token_id = vocab['[PAD]']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the BiLSTM model using **paddlenlp.models** and load pretrained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0328 13:11:28.445207 20572 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.4, Runtime API Version: 10.2\n",
      "W0328 13:11:28.449889 20572 device_context.cc:465] device: 0, cuDNN Version: 7.6.\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "import paddlenlp\n",
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F\n",
    "\n",
    "class LSTMModel(nn.Layer):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 num_classes,\n",
    "                 emb_dim=128,\n",
    "                 padding_idx=0,\n",
    "                 lstm_hidden_size=198,\n",
    "                 direction='forward',\n",
    "                 lstm_layers=1,\n",
    "                 dropout_rate=0.0,\n",
    "                 pooling_type=None,\n",
    "                 fc_hidden_size=96):\n",
    "        super().__init__()\n",
    "\n",
    "        # 首先将输入word id 查表后映射成 word embedding\n",
    "        self.embedder = nn.Embedding(\n",
    "            num_embeddings=vocab_size,\n",
    "            embedding_dim=emb_dim,\n",
    "            padding_idx=padding_idx)\n",
    "\n",
    "        # 将word embedding经过LSTMEncoder变换到文本语义表征空间中\n",
    "        self.lstm_encoder = paddlenlp.seq2vec.LSTMEncoder(\n",
    "            emb_dim,\n",
    "            lstm_hidden_size,\n",
    "            num_layers=lstm_layers,\n",
    "            direction=direction,\n",
    "            dropout=dropout_rate,\n",
    "            pooling_type=pooling_type)\n",
    "\n",
    "        # LSTMEncoder.get_output_dim()方法可以获取经过encoder之后的文本表示hidden_size\n",
    "        self.fc = nn.Linear(self.lstm_encoder.get_output_dim(), fc_hidden_size)\n",
    "\n",
    "        # 最后的分类器\n",
    "        self.output_layer = nn.Linear(fc_hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, text, seq_len):\n",
    "        # Shape: (batch_size, num_tokens, embedding_dim)\n",
    "        embedded_text = self.embedder(text)\n",
    "\n",
    "        # Shape: (batch_size, num_tokens, num_directions*lstm_hidden_size)\n",
    "        # num_directions = 2 if direction is 'bidirectional' else 1\n",
    "        text_repr = self.lstm_encoder(embedded_text, sequence_length=seq_len)\n",
    "\n",
    "\n",
    "        # Shape: (batch_size, fc_hidden_size)\n",
    "        fc_out = paddle.tanh(self.fc(text_repr))\n",
    "\n",
    "        # Shape: (batch_size, num_classes)\n",
    "        logits = self.output_layer(fc_out)\n",
    "        return logits\n",
    "\n",
    "model = LSTMModel(\n",
    "    len(vocab),\n",
    "    2,\n",
    "    direction='bidirectional',\n",
    "    padding_idx=vocab['[PAD]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS_PATH = 'assets/chnsenticorp-bilstm/final.pdparams'\n",
    "state_dict = paddle.load(PARAMS_PATH)\n",
    "model.set_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a preprocessing function that takes in **a raw string** and outputs the model inputs that can be fed into paddle_model.\n",
    "\n",
    "In this case, the raw string is splitted and mapped to word ids. *texts* is a list of lists, where each list contains a sequence of padded word ids. *seq_lens* is a list that contains the sequence length of each unpadded word ids in *texts*. \n",
    "\n",
    "Since the input data is a single raw string. Both *texts* and *seq_lens* has length 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_fn(text):\n",
    "    texts = []\n",
    "    seq_lens = []\n",
    "\n",
    "    tokens = \" \".join(jieba.cut(text)).split(' ')\n",
    "    ids = []\n",
    "    unk_id = vocab.get('[UNK]', None)\n",
    "    for token in tokens:\n",
    "        wid = vocab.get(token, unk_id)\n",
    "        if wid:\n",
    "            ids.append(wid)\n",
    "    texts.append(ids)\n",
    "    seq_lens.append(len(ids))\n",
    "\n",
    "    pad_token_id = 0\n",
    "    max_seq_len = max(seq_lens)\n",
    "\n",
    "    texts = paddle.to_tensor(texts)\n",
    "    seq_lens = paddle.to_tensor(seq_lens)\n",
    "    return texts, seq_lens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the first 1200 samples in the training set as our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddlenlp.datasets import load_dataset\n",
    "DATASET_NAME = 'chnsenticorp'\n",
    "train_ds, dev_ds, test_ds = load_dataset(\n",
    "    DATASET_NAME, splits=[\"train\", \"dev\", \"test\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total of 1200 sentences\n"
     ]
    }
   ],
   "source": [
    "data = [d['text'] for d in list(train_ds)[:1200]]\n",
    "print('total of %d sentences' % len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the `NormLIMENLPInterpreter`. We save the temporary results into a *.npz* file so that we don't have to run the whole process again if we want to rerun the same dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "normlime = it.NormLIMENLPInterpreter(model, device='gpu:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin `interpret`ing the whole dataset. This may take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "normlime_weights = normlime.interpret(\n",
    "    data,\n",
    "    preprocess_fn,\n",
    "    unk_id=unk_token_id,\n",
    "    pad_id=pad_token_id,\n",
    "    num_samples=500,\n",
    "    batch_size=50, \n",
    "    temp_data_file='assets/all_lime_weights_nlp.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cells below, we print the words with top 20 largest weights for positive and negative sentiments. Only words that appear at least 5 times are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>每次</td>\n",
       "      <td>0.031743</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>实惠</td>\n",
       "      <td>0.024094</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>精致</td>\n",
       "      <td>0.022729</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>很漂亮</td>\n",
       "      <td>0.019890</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>超值</td>\n",
       "      <td>0.015587</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>小巧</td>\n",
       "      <td>0.013401</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>没得说</td>\n",
       "      <td>0.013223</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>时尚</td>\n",
       "      <td>0.012933</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>大方</td>\n",
       "      <td>0.012203</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>出差</td>\n",
       "      <td>0.011033</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>电子版</td>\n",
       "      <td>0.010976</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>窗外</td>\n",
       "      <td>0.010734</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>一句</td>\n",
       "      <td>0.010552</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>样子</td>\n",
       "      <td>0.010286</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>轻</td>\n",
       "      <td>0.010010</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>价位</td>\n",
       "      <td>0.009736</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>强劲</td>\n",
       "      <td>0.009232</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>总体</td>\n",
       "      <td>0.007775</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>五星</td>\n",
       "      <td>0.007419</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>舒适</td>\n",
       "      <td>0.007411</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word    weight  frequency\n",
       "0    每次  0.031743         12\n",
       "1    实惠  0.024094         10\n",
       "2    精致  0.022729          5\n",
       "3   很漂亮  0.019890         11\n",
       "4    超值  0.015587         11\n",
       "5    小巧  0.013401         12\n",
       "6   没得说  0.013223          5\n",
       "7    时尚  0.012933          7\n",
       "8    大方  0.012203          5\n",
       "9    出差  0.011033          6\n",
       "10  电子版  0.010976          5\n",
       "11   窗外  0.010734          6\n",
       "12   一句  0.010552          6\n",
       "13   样子  0.010286         15\n",
       "14    轻  0.010010          6\n",
       "15   价位  0.009736         10\n",
       "16   强劲  0.009232          6\n",
       "17   总体  0.007775         30\n",
       "18   五星  0.007419          5\n",
       "19   舒适  0.007411         10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "id2word = dict(zip(vocab.values(), vocab.keys()))\n",
    "# Positive \n",
    "temp = {\n",
    "    id2word[wid]: normlime_weights[1][wid]\n",
    "    for wid in normlime_weights[1]\n",
    "}\n",
    "W = [(word, weight[0], weight[1]) for word, weight in temp.items() if  weight[1] >= 5]\n",
    "pd.DataFrame(data = sorted(W, key=lambda x: -x[1])[:20], columns = ['word', 'weight', 'frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>很差</td>\n",
       "      <td>0.043360</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>穴位</td>\n",
       "      <td>0.033197</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>偏</td>\n",
       "      <td>0.029332</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>差</td>\n",
       "      <td>0.023744</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>宣传</td>\n",
       "      <td>0.021885</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>缺点</td>\n",
       "      <td>0.021287</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>声卡</td>\n",
       "      <td>0.021061</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>求医</td>\n",
       "      <td>0.020905</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>发热量</td>\n",
       "      <td>0.018769</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>热</td>\n",
       "      <td>0.017466</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>不合理</td>\n",
       "      <td>0.016707</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>失望</td>\n",
       "      <td>0.016628</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>极差</td>\n",
       "      <td>0.016496</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>太小</td>\n",
       "      <td>0.013610</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>发热</td>\n",
       "      <td>0.013471</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>内容</td>\n",
       "      <td>0.012045</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>重</td>\n",
       "      <td>0.012029</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>一般</td>\n",
       "      <td>0.012026</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>简直</td>\n",
       "      <td>0.011874</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>风扇</td>\n",
       "      <td>0.011805</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word    weight  frequency\n",
       "0    很差  0.043360         13\n",
       "1    穴位  0.033197          5\n",
       "2     偏  0.029332          5\n",
       "3     差  0.023744         62\n",
       "4    宣传  0.021885          5\n",
       "5    缺点  0.021287          9\n",
       "6    声卡  0.021061          6\n",
       "7    求医  0.020905          6\n",
       "8   发热量  0.018769          8\n",
       "9     热  0.017466         21\n",
       "10  不合理  0.016707          5\n",
       "11   失望  0.016628         40\n",
       "12   极差  0.016496          6\n",
       "13   太小  0.013610         18\n",
       "14   发热  0.013471          7\n",
       "15   内容  0.012045         46\n",
       "16    重  0.012029         11\n",
       "17   一般  0.012026         57\n",
       "18   简直  0.011874         17\n",
       "19   风扇  0.011805          7"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Negative\n",
    "temp = {\n",
    "    id2word[wid]: normlime_weights[0][wid]\n",
    "    for wid in normlime_weights[0]\n",
    "}\n",
    "W = [(word, weight[0], weight[1]) for word, weight in temp.items() if  weight[1] >= 5]\n",
    "pd.DataFrame(data = sorted(W, key=lambda x: -x[1])[:20], columns = ['word', 'weight', 'frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pp2",
   "language": "python",
   "name": "pp2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
